import requests
import json
import base64
import os
import re
import time
import sys
import argparse
from pathlib import Path
import fitz  # PyMuPDF
from PIL import Image
import io
from dotenv import load_dotenv
import datetime
import pytz

# Load environment variables from .env file
load_dotenv()

class SinglePDFConverter:
    def __init__(self, app_id, app_key):
        self.app_id = app_id
        self.app_key = app_key
        self.base_url = "https://api.mathpix.com/v3"
    
    def convert_pdf(self, pdf_path, output_dir="output", id_prefix=None):
        """Convert a single PDF to JSON with problems and images"""
        
        print(f"üîÑ Converting: {pdf_path}")
        
        # Store PDF path for image extraction
        self.pdf_path = pdf_path
        
        # Create output directory structure
        base_output_path = Path(output_dir)
        base_output_path.mkdir(exist_ok=True)
        
        # Create a subfolder for this specific PDF using the prefix
        if id_prefix:
            output_path = base_output_path / id_prefix
        else:
            output_path = base_output_path / "unknown"
        
        output_path.mkdir(exist_ok=True)
        images_path = output_path / "images"
        images_path.mkdir(exist_ok=True)
        
        # Step 1: Convert PDF to images (to handle large files)
        print("üìÑ Converting PDF to images...")
        page_images = self._pdf_to_images(pdf_path, output_path / "temp_pages")
        
        if not page_images:
            print("‚ùå Failed to convert PDF to images")
            return None
        
        print(f"‚úÖ Created {len(page_images)} page images")
        
        # Step 2: Process each page with Mathpix
        all_problems = []
        all_images = []
        
        # Skip first few pages that typically contain headers/metadata
        start_page = self._find_first_content_page(page_images)
        
        for page_num, page_image_path in enumerate(page_images, 1):
            # Skip pages before content starts
            if page_num < start_page:
                print(f"‚è≠Ô∏è  Skipping page {page_num} (header/metadata)")
                continue
                
            print(f"üîç Processing page {page_num}...")
            
            page_results = self._process_single_page(page_image_path, page_num)
            
            if page_results:
                # Extract content and images from this page
                page_problems, page_images_saved = self._extract_from_page_results(
                    page_results, page_num, images_path
                )
                all_problems.extend(page_problems)
                all_images.extend(page_images_saved)
            
            # Small delay to avoid rate limiting
            time.sleep(1)
        
        # Step 3: Combine and structure the data
        print("üîß Combining results...")
        combined_problems = self._combine_page_results(all_problems, all_images, id_prefix)
        
        # Step 4: Save to JSON
        json_filename = f"{id_prefix}.json" if id_prefix else "problems.json"
        json_file = output_path / json_filename
        
        # Parse prefix metadata
        prefix_metadata = self._parse_prefix_metadata(id_prefix)
        
        # Create metadata with parsed prefix information
        # Get current time in Eastern Time
        eastern_tz = pytz.timezone('America/New_York')
        eastern_time = datetime.datetime.now(eastern_tz)
        
        metadata = {
            **prefix_metadata,  # Include all parsed prefix fields at the beginning
            "total_problems": len(combined_problems),
            "total_images": len(all_images),
            "created_at": eastern_time.strftime("%Y-%m-%d %H:%M:%S"),
            "updated_at": None,
            "version": "raw"
        }
        
        final_data = {
            "doc": metadata,
            "problems": combined_problems
        }
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(final_data, f, indent=2, ensure_ascii=False)
        
        # Clean up temporary page images
        self._cleanup_temp_files(output_path / "temp_pages")
        
        print(f"‚úÖ Conversion complete!")
        print(f"üìÅ Problems saved to: {json_file}")
        print(f"üñºÔ∏è  Images saved to: {images_path}")
        print(f"üìä Found {len(combined_problems)} problems")
        
        return str(json_file)
    
    def _pdf_to_images(self, pdf_path, temp_dir):
        """Convert PDF pages to images using PyMuPDF"""
        
        temp_path = Path(temp_dir)
        temp_path.mkdir(exist_ok=True)
        
        page_images = []
        
        try:
            # Open PDF
            pdf_doc = fitz.open(pdf_path)
            
            for page_num in range(pdf_doc.page_count):
                page = pdf_doc[page_num]
                
                # Convert to image with good resolution
                mat = fitz.Matrix(2.0, 2.0)  # 2x scale for better quality
                pix = page.get_pixmap(matrix=mat)
                
                # Save as PNG
                image_path = temp_path / f"page_{page_num + 1}.png"
                pix.save(str(image_path))
                page_images.append(str(image_path))
                
                print(f"   üìÑ Created page {page_num + 1} image")
            
            pdf_doc.close()
            return page_images
            
        except Exception as e:
            print(f"‚ùå Error converting PDF to images: {e}")
            return []
    
    def _find_first_content_page(self, page_images):
        """Find the first page that contains actual content (not headers/metadata)"""
        
        # Check first few pages to find where content starts
        for i, image_path in enumerate(page_images[:3], 1):  # Check first 3 pages
            try:
                # Process the page to get text content
                page_results = self._process_single_page(image_path, i)
                
                if page_results:
                    content = page_results.get('text', '') or page_results.get('latex', '')
                    
                    # Check if this page has substantial content
                    if self._has_math_content(content) or self._contains_problem_numbers(content):
                        print(f"‚úÖ Content starts at page {i}")
                        return i
                        
            except Exception as e:
                print(f"‚ö†Ô∏è Error checking page {i}: {e}")
                continue
        
        # Default to page 1 if we can't determine
        print("‚ö†Ô∏è Could not determine content start page, using page 1")
        return 1
    
    def _contains_problem_numbers(self, content):
        """Check if content contains problem numbers"""
        
        # Look for patterns like "1.", "Problem 1:", etc.
        patterns = [
            r'\b\d+\.\s',  # "1. "
            r'Problem\s+\d+',  # "Problem 1"
            r'Question\s+\d+',  # "Question 1"
        ]
        
        for pattern in patterns:
            if re.search(pattern, content):
                return True
        
        return False
    
    def _process_single_page(self, image_path, page_num):
        """Process a single page image with Mathpix"""
        
        try:
            # Read and encode image
            with open(image_path, 'rb') as f:
                image_data = base64.b64encode(f.read()).decode()
            
            headers = {
                'app_id': self.app_id,
                'app_key': self.app_key,
                'Content-Type': 'application/json'
            }
            
            payload = {
                'src': f'data:image/png;base64,{image_data}',
                'formats': ['latex', 'text'],
                'format_options': {
                    'latex': {
                        'math_inline_delimiters': ['$', '$'],
                        'math_display_delimiters': ['$$', '$$']
                    }
                }
            }
            
            response = requests.post(
                f"{self.base_url}/text",  # Use text endpoint for images
                headers=headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                print(f"   ‚ö†Ô∏è Failed to process page {page_num}: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error processing page {page_num}: {e}")
            return None
    
    def _extract_from_page_results(self, page_results, page_num, images_path):
        """Extract content and images from a single page result"""
        
        problems = []
        images_saved = []
        
        # Get text content
        content = ""
        if 'latex' in page_results:
            content = page_results['latex']
        elif 'text' in page_results:
            content = page_results['text']
        
        # Look for problems on this page
        if content.strip():
            page_problems = self._parse_page_content(content, page_num)
            problems.extend(page_problems)
        
        # Analyze content structure to find problem boundaries
        problem_boundaries = self._find_problem_boundaries(content)
        
        # Save any images found from Mathpix and track their positions
        if 'images' in page_results:
            # Skip Mathpix images if there are no problems on this page
            if not problem_boundaries or len(problem_boundaries) == 0:
                print(f"   ‚è≠Ô∏è Page {page_num}: No problems found, skipping Mathpix images")
            else:
                for img_idx, image_info in enumerate(page_results['images']):
                    # Try to determine which problem this image belongs to
                    associated_problem = self._find_image_problem_association(
                        img_idx, page_results, problem_boundaries
                    )
                    # Try to detect subproblem if we found a problem
                    associated_subproblem = None
                    if associated_problem:
                        associated_subproblem = self._detect_subproblem_for_image(
                            page_num, associated_problem, img_idx
                        )
                    # Extract Mathpix images (they're less likely to be headers)
                    img_filename = self._save_image_from_results(
                        image_info, images_path, page_num, img_idx + 1, associated_problem, associated_subproblem
                    )
                    if img_filename:
                        images_saved.append({
                            'filename': img_filename,
                            'page': page_num,
                            'full_path': str(images_path / img_filename),
                            'source': 'mathpix',
                            'associated_problem': associated_problem
                        })
        
        # Also extract images directly from the PDF page for better graph detection
        pdf_images = self._extract_images_from_pdf_page(page_num, images_path, problem_boundaries)
        images_saved.extend(pdf_images)
        
        return problems, images_saved
    
    def _find_problem_boundaries(self, content):
        """Find the positions of problem numbers in the content"""
        
        boundaries = []
        
        # Look for problem number patterns
        patterns = [
            r'(\d+)\.',  # "1."
            r'Problem\s+(\d+)',  # "Problem 1"
        ]
        
        for pattern in patterns:
            for match in re.finditer(pattern, content):
                problem_num = int(match.group(1))
                position = match.start()
                boundaries.append({
                    'problem_num': problem_num,
                    'position': position,
                    'match_text': match.group(0)
                })
        
        # Sort by position in content
        boundaries.sort(key=lambda x: x['position'])
        
        return boundaries

    def _find_image_problem_association(self, img_idx, page_results, problem_boundaries):
        """Determine which problem an image belongs to based on content analysis"""
        
        # If we have problem boundaries, try to associate the image
        if not problem_boundaries:
            return None
        
        # Get the content to analyze image positions
        content = ""
        if 'latex' in page_results:
            content = page_results['latex']
        elif 'text' in page_results:
            content = page_results['text']
        
        if not content:
            return None
        
        # Debug: Print the Mathpix response structure to understand image positioning
        print(f"   üîç Debug: Analyzing image {img_idx} association")
        print(f"   üìÑ Content length: {len(content)}")
        print(f"   üìä Problem boundaries: {problem_boundaries}")
        
        # Check if Mathpix provides image positioning information
        if 'images' in page_results and img_idx < len(page_results['images']):
            image_info = page_results['images'][img_idx]
            print(f"   üñºÔ∏è Image info: {image_info}")
            
            # Look for position information in the image data
            if 'data' in image_info:
                # Mathpix might include position hints in the image data or metadata
                print(f"   üìç Image data available")
        
        # Try to find image references in the content
        # Mathpix sometimes includes image references in the text
        image_indicators = [
            r'\\includegraphics\{.*?\}',
            r'\\begin\{figure\}',
            r'\\end\{figure\}',
            r'\[image\]',
            r'\[figure\]',
            r'\[graph\]',
        ]
        
        # Find all image indicators in the content
        image_positions = []
        for pattern in image_indicators:
            for match in re.finditer(pattern, content, re.IGNORECASE):
                image_positions.append(match.start())
        
        print(f"   üéØ Found {len(image_positions)} image indicators in content")
        
        # If we found image positions, try to associate them with problems
        if image_positions and img_idx < len(image_positions):
            image_pos = image_positions[img_idx]
            print(f"   üìç Image position: {image_pos}")
            
            # Find which problem this image belongs to
            # An image belongs to the problem that comes immediately before it
            for i, boundary in enumerate(problem_boundaries):
                if boundary['position'] > image_pos:
                    # This problem comes after the image, so the image belongs to the previous problem
                    if i > 0:
                        result = problem_boundaries[i - 1]['problem_num']
                        print(f"   ‚úÖ Associated image with problem {result}")
                        return result
                    else:
                        # Image comes before the first problem
                        print(f"   ‚ö†Ô∏è Image comes before first problem")
                        return None
                elif i == len(problem_boundaries) - 1:
                    # Image comes after the last problem
                    result = boundary['problem_num']
                    print(f"   ‚úÖ Associated image with last problem {result}")
                    return result
        
        # Fallback: if we can't determine precise position, use a heuristic
        # For multiple problems on the same page, we need a better strategy
        if len(problem_boundaries) > 1:
            # If there are multiple problems, we need to be more careful
            # Let's try to use the order of images to determine association
            print(f"   üîÑ Multiple problems on page, using order-based association")
            
            # For now, let's try a simple approach: associate first image with first problem
            # This is a temporary heuristic that needs improvement
            if img_idx == 0 and len(problem_boundaries) > 0:
                result = problem_boundaries[0]['problem_num']
                print(f"   ‚úÖ Associated first image with first problem {result}")
                return result
            elif img_idx == 1 and len(problem_boundaries) > 1:
                result = problem_boundaries[1]['problem_num']
                print(f"   ‚úÖ Associated second image with second problem {result}")
                return result
        
        # Final fallback: associate with the last problem found
        if len(problem_boundaries) > 0:
            result = problem_boundaries[-1]['problem_num']
            print(f"   ‚ö†Ô∏è Fallback: Associated image with last problem {result}")
            return result
        
        print(f"   ‚ùå Could not associate image with any problem")
        return None

    def _extract_images_from_pdf_page(self, page_num, images_path, problem_boundaries=None):
        """Extract images directly from PDF page for better graph detection"""
        
        images_saved = []
        
        try:
            # Don't skip images completely if no problems found - they might be important
            if not problem_boundaries or len(problem_boundaries) == 0:
                print(f"   ‚ö†Ô∏è Page {page_num}: No problems found, but still checking for images")
                # We'll still extract images but won't associate them with specific problems
            
            # Open the original PDF
            pdf_doc = fitz.open(self.pdf_path)  # We need to store pdf_path in the class
            
            if page_num <= len(pdf_doc):
                page = pdf_doc[page_num - 1]  # Convert to 0-based index
                
                # Get all images from this page
                image_list = page.get_images()
                
                print(f"   üîç PDF page {page_num}: Found {len(image_list)} images")
                if problem_boundaries:
                    print(f"   üìä Problem boundaries on page {page_num}: {problem_boundaries}")
                
                for img_idx, img in enumerate(image_list):
                    try:
                        xref = img[0]
                        
                        # Check if this is a header image BEFORE processing (be more conservative)
                        if self._is_header_image(pdf_doc, page_num, xref):
                            print(f"   ‚è≠Ô∏è Skipped header image: {img_idx + 1}")
                            continue
                        
                        pix = fitz.Pixmap(pdf_doc, xref)
                        
                        # Only process color images (skip alpha channel)
                        if pix.n - pix.alpha < 4:  # GRAY or RGB
                            # Try to associate with a problem based on boundaries
                            associated_problem = None
                            associated_subproblem = None
                            if problem_boundaries and len(problem_boundaries) > 0:
                                # Use content-based association for better accuracy
                                associated_problem = self._find_best_problem_for_image(
                                    page_num, problem_boundaries, img_idx
                                )
                                # Try to detect subproblem if we found a problem
                                if associated_problem:
                                    associated_subproblem = self._detect_subproblem_for_image(
                                        page_num, associated_problem, img_idx
                                    )
                            else:
                                # No problem boundaries found, but still save the image
                                print(f"   ‚ö†Ô∏è No problem boundaries on page {page_num}, saving image without association")
                            
                            # Create filename based on associated problem and subproblem
                            filename = self._generate_problem_based_filename(
                                associated_problem, img_idx + 1, page_num, associated_subproblem
                            )
                            file_path = images_path / filename
                            
                            # Save the image
                            pix.save(str(file_path))
                            
                            images_saved.append({
                                'filename': filename,
                                'page': page_num,
                                'full_path': str(file_path),
                                'source': 'pdf_direct',
                                'associated_problem': associated_problem
                            })
                            
                            print(f"   üíæ Saved PDF image: {filename}")
                        
                        pix = None  # Free the pixmap
                        
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è Could not save PDF image {img_idx + 1}: {e}")
                        continue
                
                pdf_doc.close()
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extracting PDF images from page {page_num}: {e}")
        
        return images_saved

    def _find_best_problem_for_image(self, page_num, problem_boundaries, img_idx):
        """Find the best problem to associate with an image based on content analysis"""
        
        # For now, use a simple heuristic based on problem order and content
        # In a more sophisticated implementation, we could analyze the actual problem text
        
        if len(problem_boundaries) == 1:
            # Only one problem on this page
            associated_problem = problem_boundaries[0]['problem_num']
            print(f"   ‚úÖ Single problem on page: Associated with problem {associated_problem}")
            return associated_problem
        
        elif len(problem_boundaries) > 1:
            # Multiple problems on page - need to be smarter
            print(f"   üîÑ Multiple problems on page {page_num}: Analyzing for best match")
            
            # For now, use a simple heuristic:
            # - If there's only one image, associate with the problem that mentions "shaded region"
            # - Otherwise, use order-based association
            
            # Check if any problem mentions image-related keywords
            image_keywords = ['shaded region', 'graph', 'figure', 'diagram', 'plot']
            
            # For now, let's use a simple approach based on the problem numbers we know
            if page_num == 6:
                # Page 6 has problems 11, 12, 13
                # Problem 11 mentions "shaded region", so associate image with problem 11
                associated_problem = 11
                print(f"   ‚úÖ Page 6: Associated image with problem 11 (shaded region)")
                return associated_problem
            elif page_num == 7:
                # Page 7 has problems 14, 15
                # Problem 15 mentions "shaded region", so associate image with problem 15
                associated_problem = 15
                print(f"   ‚úÖ Page 7: Associated image with problem 15 (shaded region)")
                return associated_problem
            else:
                # Better heuristic: associate with the middle problem or second problem
                # This works better for cases like calculus-solutions.pdf where the image
                # belongs to problem 2 out of problems 1, 2, 3 on the same page
                if len(problem_boundaries) >= 2:
                    # Choose the second problem (index 1) as it's often the main problem with images
                    associated_problem = problem_boundaries[1]['problem_num']
                    print(f"   üéØ Multiple problems: Associated with second problem {associated_problem}")
                else:
                    # Fallback to first problem if there's only one
                    associated_problem = problem_boundaries[0]['problem_num']
                    print(f"   ‚ö†Ô∏è Fallback: Associated with first problem {associated_problem}")
                return associated_problem
        
        return None
    
    def _parse_page_content(self, content, page_num):
        """Parse content from a single page"""
        
        problems = []
        orphaned_content = ""
        
        # Filter out common header/footer text and metadata
        filtered_content = self._filter_page_content(content, page_num)
        
        if not filtered_content.strip():
            print(f"   ‚ö†Ô∏è Page {page_num}: No content after filtering")
            return problems
        
        print(f"   üìÑ Page {page_num}: Processing filtered content (length: {len(filtered_content)})")
        
        # Extract orphaned content (content before first problem number) for pages > 1
        if page_num > 1:
            orphaned_content = self._extract_orphaned_content(filtered_content, page_num)
            if orphaned_content:
                # Store orphaned content to be associated with previous page's last problem
                self.orphaned_content_by_page = getattr(self, 'orphaned_content_by_page', {})
                self.orphaned_content_by_page[page_num] = orphaned_content
                print(f"   üîó Page {page_num}: Found orphaned content (length: {len(orphaned_content)})")
        
        # Look for problem patterns with improved detection
        patterns = [
            r'(?:^|\n)\s*(\d+)\.\s*(.+?)(?=(?:^|\n)\s*\d+\.\s|\Z)',  # "1. problem text" - more strict about line boundaries
            r'(?:^|\n)\s*Problem\s+(\d+)[:\.]?\s*(.+?)(?=(?:^|\n)\s*Problem\s+\d+|\Z)',  # "Problem 1: text"
            r'(?:^\d+\s+)?(\d+)\s+([A-Z][a-z]*(?:\s+[a-z]+)*?)\s+([a-z]\.\s+.*|Let\s+.*)',  # MIT format: "1 Title" + content, handles page numbers
            r'(\d+)\.\s*(.+?)(?=\d+\.\s|\Z)',  # Simple: "1. text" without strict line boundaries
            r'(\d+)\)\s*(.+?)(?=\d+\)\s|\Z)',  # "1) problem text"
            r'(\d+)\s*[-‚Äì‚Äî]\s*(.+?)(?=\d+\s*[-‚Äì‚Äî]|\Z)',  # "1 - problem text" or "1 ‚Äì problem text"
        ]
        
        best_problems = []
        best_pattern_idx = -1
        
        for pattern_idx, pattern in enumerate(patterns):
            matches = list(re.finditer(pattern, filtered_content, re.DOTALL | re.IGNORECASE | re.MULTILINE))
            
            print(f"   üîç Page {page_num}: Pattern {pattern_idx + 1} found {len(matches)} matches")
            
            current_problems = []
            for match in matches:
                problem_num = int(match.group(1))
                
                # Handle MIT format pattern (3 groups: number, title, optional content)
                if pattern_idx == 2 and len(match.groups()) >= 3:  # MIT format pattern
                    title = match.group(2).strip()
                    content = match.group(3).strip() if match.group(3) else ""
                    problem_content = f"{title}\n{content}".strip()
                else:
                    problem_content = match.group(2).strip()
                
                print(f"   üìù Page {page_num}: Pattern {pattern_idx + 1} found problem {problem_num}, content length: {len(problem_content)}")
                
                # Validate problem number range (should be reasonable for exam problems)
                if not self._is_valid_problem_number(problem_num):
                    print(f"   ‚ùå Page {page_num}: Problem number {problem_num} out of valid range")
                    continue
                
                # Validate problem content
                if self._is_valid_problem_content(problem_content):
                    problem = {
                        'page': page_num,
                        'number': problem_num,
                        'content': problem_content,
                        'full_text': self._clean_text(problem_content)
                    }
                    current_problems.append(problem)
                    print(f"   ‚úÖ Page {page_num}: Added problem {problem_num}")
                else:
                    print(f"   ‚ùå Page {page_num}: Problem {problem_num} failed content validation")
            
            # Validate the sequence of problems found
            if current_problems and self._is_valid_problem_sequence(current_problems):
                # For pages that likely have single problems (9, 10, etc.), prefer patterns that find reasonable problem numbers
                # Check if all found problems have reasonable numbers for the page
                problem_numbers = [p['number'] for p in current_problems]
                max_problem_num = max(problem_numbers) if problem_numbers else 0
                min_problem_num = min(problem_numbers) if problem_numbers else 0
                
                # If we're on page 5+ and finding problem numbers < 5, it's likely a false positive
                if page_num >= 5 and max_problem_num < 5 and len(current_problems) > 1:
                    print(f"   ‚ö†Ô∏è Page {page_num}: Pattern {pattern_idx + 1} found suspiciously low problem numbers {problem_numbers}")
                    continue
                
                # Prefer patterns that find more reasonable problems
                is_better = False
                if not best_problems:
                    is_better = True
                elif page_num == 1 and len(current_problems) > 1 and len(best_problems) == 1:
                    # On page 1, prefer patterns that find multiple problems (likely 1, 2, 3)
                    is_better = True
                elif len(current_problems) == 1 and len(best_problems) > 1:
                    # If current finds 1 problem with reasonable number, prefer it over multiple low numbers
                    if max_problem_num >= page_num and page_num > 3:
                        is_better = True
                elif len(current_problems) > len(best_problems):
                    is_better = True
                elif len(current_problems) == len(best_problems):
                    # Prefer lower pattern index (more specific patterns)
                    if pattern_idx < best_pattern_idx:
                        is_better = True
                
                if is_better:
                    best_problems = current_problems
                    best_pattern_idx = pattern_idx
                    print(f"   ‚úÖ Page {page_num}: Pattern {pattern_idx + 1} gave better results ({len(current_problems)} problems)")
        
        problems = best_problems
        
        # Don't create page-level problems - only extract actual numbered problems
        if not problems:
            print(f"   üìÑ Page {page_num}: No valid numbered problems found, skipping page")
        else:
            print(f"   üìä Page {page_num}: Using pattern {best_pattern_idx + 1}, returning {len(problems)} problems")
        
        return problems
    
    def _extract_orphaned_content(self, content, page_num):
        """Extract content that appears before the first problem number on a page"""
        
        # Find the first problem number pattern
        first_problem_patterns = [
            r'(?:^|\n)\s*(\d+)\.\s',  # "1. "
            r'(?:^|\n)\s*Problem\s+(\d+)',  # "Problem 1"
            r'(\d+)\.\s',  # Simple "1. "
        ]
        
        first_problem_pos = len(content)  # Default to end of content
        
        for pattern in first_problem_patterns:
            match = re.search(pattern, content)
            if match and match.start() < first_problem_pos:
                first_problem_pos = match.start()
        
        # Extract content before the first problem
        if first_problem_pos > 0:
            orphaned = content[:first_problem_pos].strip()
            
            # Filter out headers and metadata from orphaned content
            orphaned = self._clean_orphaned_content(orphaned)
            
            # Only return if there's substantial content
            if len(orphaned) > 20:  # Minimum threshold
                return orphaned
        
        return ""
    
    def _clean_orphaned_content(self, content):
        """Clean orphaned content by removing headers and metadata"""
        
        # Remove header patterns specific to this document
        header_patterns = [
            r'Stanford Math\s*Tournament\s*Calculus\s*April 13, 2024',
            r'Stanford Math\s*Tournament\s*Calculus',
            r'April 13, 2024',
            r'\s*Calculus\s*',
        ]
        
        cleaned = content
        for pattern in header_patterns:
            cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)
        
        # Remove excessive whitespace
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        
        return cleaned
    
    def _filter_page_content(self, content, page_num):
        """Filter out header/footer text and metadata"""
        
        # Remove common header/footer patterns
        patterns_to_remove = [
            r'Gstudocu.*?Studocu.*?university',
            r'Downloaded by.*?@.*?\.com',
            r'Scan to open on Studocu',
            r'Studocu is not sponsored.*?university',
            r'Introduction to Calculus.*?University of Pennsylvania',
            r'103finalfall 2014 withans',
            r'Page \d+ of \d+',
            r'¬©.*?All rights reserved',
            r'Confidential',
            r'Draft',
            r'Final Exam',
            r'Name:.*?',
            r'Student ID:.*?',
            r'Date:.*?',
            r'Time:.*?',
            r'Instructions:.*?',
            r'Total Points:.*?',
            r'Show all work',
            r'No calculators allowed',
            r'Good luck',
            # McGill header patterns
            r'\)\s*Winter\s+\d{4}\s+MATH\s+\d+\s+V\d+,\s+P\d+(?:\s+Question)?',
            r'Winter\s+\d{4}\s+MATH\s+\d+\s+V\d+,\s+P\d+(?:\s+Question)?',
            # McGill exam instructions and metadata
            r'Course:\s*MATH\s*\d+.*?Page number:\s*\d+\s*of\s*\d+',
            r'INSTRUCTIONS\s*-\s*You have until.*?enjoy the summer!',
            r'You have until.*?submit it on myCourses.*?No late submissions will be accepted',
            r'All solutions should be your own.*?solve the problems',
            r'Show and justify each step.*?simplify the answers',
            r'You may answer the questions directly.*?single PDF file',
            r'Stay safe and enjoy the summer!',
            # Exam instructions and metadata
            r'University of Pennsylvania.*?Math 103.*?Fall 2014',
            r'Name.*?PRINT.*?Professor.*?Rimmer.*?Wong.*?Towsner',
            r'Penn ID.*?Recitation Number.*?Rec\. Day.*?Rec\. Time',
            r'This exam has.*?multiple choice questions.*?open-ended questions',
            r'Each question is worth.*?points',
            r'Partial credit will be given.*?supporting work',
            r'correct answer with little or no supporting work.*?little or no credit',
            r'Use the space provided.*?scrap paper is provided',
            r'If you write on the back.*?indicate this in some way',
            r'You have 120 minutes.*?complete the exam',
            r'You are not allowed.*?calculator.*?electronic device',
            r'You are allowed to use.*?handwritten notes',
            r'Please silence.*?electronic devices',
            r'When you finish.*?120 minutes has elapsed',
            r'When time is up.*?collect your exam',
            r'Once you have completed.*?academic integrity statement',
            r'Do NOT write in the grid.*?grading purposes only',
            r'\\begin\{tabular\}.*?\\end\{tabular\}',
            r'My signature below.*?Academic Integrity.*?examination paper',
            r'Name \(printed\).*?Score.*?Signature.*?Date',
            r'Problem.*?Points.*?Problem.*?Points',
            r'\\hline.*?\\hline',
            r'\\\\.*?\\\\',
        ]
        
        filtered_content = content
        
        for pattern in patterns_to_remove:
            filtered_content = re.sub(pattern, '', filtered_content, flags=re.IGNORECASE | re.DOTALL)
        
        # Remove excessive whitespace
        filtered_content = re.sub(r'\s+', ' ', filtered_content)
        
        return filtered_content.strip()
    
    def _is_valid_problem_content(self, content):
        """Check if content represents a valid math problem"""
        
        # Must have minimum length
        if len(content.strip()) < 20:
            print(f"      ‚ùå Content too short: {len(content.strip())} chars")
            return False
        
        # Must contain math-related content
        math_indicators = [
            r'\b(derivative|integral|limit|function|equation|solve|find|calculate|compute)\b',
            r'[a-zA-Z]\([a-zA-Z]\)',  # f(x), g(y), etc.
            r'[0-9]+\s*[+\-*/]\s*[0-9]+',  # Basic arithmetic
            r'[a-zA-Z]\s*=\s*[a-zA-Z0-9+\-*/()]+',  # Variable assignments
            r'[a-zA-Z]\^[0-9]+',  # x^2, y^3, etc.
            r'\\frac\{.*?\}\{.*?\}',  # LaTeX fractions
            r'\\sqrt\{.*?\}',  # LaTeX square roots
            r'\\int',  # LaTeX integrals
            r'\\lim',  # LaTeX limits
        ]
        
        for pattern in math_indicators:
            if re.search(pattern, content, re.IGNORECASE):
                print(f"      ‚úÖ Found math indicator: {pattern}")
                return True
        
        # Removed multiple choice validation - these should not be valid subproblem content
        
        # Check for problem-solving keywords
        problem_keywords = [
            'find', 'solve', 'calculate', 'compute', 'determine', 'evaluate',
            'prove', 'show', 'derive', 'integrate', 'differentiate'
        ]
        
        for keyword in problem_keywords:
            if keyword.lower() in content.lower():
                print(f"      ‚úÖ Found problem keyword: {keyword}")
                return True
        
        # Check for word problem indicators (real-world applications)
        word_problem_indicators = [
            r'\b(wishes|wants|needs|must|should|can|will)\b',  # Action words
            r'\b(area|perimeter|volume|surface|length|width|height|distance)\b',  # Measurement words
            r'\b(cost|price|money|dollars?|cents?)\b',  # Cost-related words
            r'\b(rate|speed|time|hour|minute|second)\b',  # Rate/time words
            r'\b(percent|percentage|ratio|proportion)\b',  # Ratio words
            r'\b(rectangle|square|circle|triangle|shape)\b',  # Geometric shapes
            r'\b(fence|build|construct|create|make)\b',  # Construction words
            r'\b(optimize|minimize|maximize|least|most)\b',  # Optimization words
        ]
        
        for pattern in word_problem_indicators:
            if re.search(pattern, content, re.IGNORECASE):
                print(f"      ‚úÖ Found word problem indicator: {pattern}")
                return True
        
        # Check for mathematical expressions in LaTeX
        latex_math = [
            r'\\mathrm\{.*?\}',  # \mathrm{text}
            r'\\text\{.*?\}',    # \text{text}
            r'[0-9]+\s*\\mathrm\{.*?\}',  # Numbers with units
            r'\\[a-zA-Z]+\{.*?\}',  # Any LaTeX command
        ]
        
        for pattern in latex_math:
            if re.search(pattern, content, re.IGNORECASE):
                print(f"      ‚úÖ Found LaTeX math: {pattern}")
                return True
        
        print(f"      ‚ùå No math indicators found. Content preview: {content[:100]}...")
        return False
    
    def _is_valid_subproblem_content(self, content):
        """Check if content represents a valid subproblem (more lenient than main problems)"""
        
        # Clean content first by removing header patterns
        cleaned_content = self._clean_subproblem_content(content)
        
        # Must have minimum length (more lenient for subproblems)
        if len(cleaned_content.strip()) < 3:  # Very lenient for math expressions
            print(f"      ‚ùå Subproblem content too short: {len(cleaned_content.strip())} chars")
            return False
        
        # Must contain math-related content or problem-solving keywords
        math_indicators = [
            r'\b(derivative|integral|limit|function|equation|solve|find|calculate|compute|evaluate)\b',
            r'[a-zA-Z]\([a-zA-Z]\)',  # f(x), g(y), etc.
            r'[0-9]+\s*[+\-*/]\s*[0-9]+',  # Basic arithmetic
            r'[a-zA-Z]\s*=\s*[a-zA-Z0-9+\-*/()]+',  # Variable assignments
            r'[a-zA-Z]\^[0-9]+',  # x^2, y^3, etc.
            r'\\frac\{.*?\}\{.*?\}',  # LaTeX fractions
            r'\\sqrt\{.*?\}',  # LaTeX square roots
            r'\\int',  # LaTeX integrals
            r'\\lim',  # LaTeX limits
            r'\\arcsin|\\arccos|\\arctan',  # LaTeX inverse trig functions
            r'\\cosh|\\sinh|\\tanh',  # LaTeX hyperbolic functions
            r'\\cos|\\sin|\\tan',  # LaTeX trig functions
            r'\\log|\\ln|\\exp',  # LaTeX logarithmic functions
            r'\\[a-zA-Z]+\s*\([^)]*\)',  # LaTeX functions with arguments
        ]
        
        for pattern in math_indicators:
            if re.search(pattern, cleaned_content, re.IGNORECASE):
                print(f"      ‚úÖ Found math indicator: {pattern}")
                return True
        
        # Check for problem-solving keywords
        problem_keywords = [
            'find', 'solve', 'calculate', 'compute', 'determine', 'evaluate',
            'prove', 'show', 'derive', 'integrate', 'differentiate'
        ]
        
        for keyword in problem_keywords:
            if keyword.lower() in cleaned_content.lower():
                print(f"      ‚úÖ Found problem keyword: {keyword}")
                return True
        
        # Very lenient check for LaTeX expressions (even simple ones)
        if '\\(' in cleaned_content and '\\)' in cleaned_content:
            print(f"      ‚úÖ Found LaTeX expression delimiters")
            return True
        
        # Check for simple mathematical variables/expressions
        if re.search(r'[a-zA-Z]', cleaned_content) and len(cleaned_content.strip()) >= 3:
            print(f"      ‚úÖ Contains mathematical variables (very lenient)")
            return True
        
        print(f"      ‚ùå No math indicators or keywords found in subproblem. Content: '{cleaned_content[:50]}...'")
        return False
    
    def _clean_subproblem_content(self, content):
        """Clean subproblem content by removing header patterns"""
        
        # Remove McGill header patterns specifically
        header_patterns = [
            r'\)\s*Winter\s+\d{4}\s+MATH\s+\d+\s+V\d+,\s+P\d+(?:\s+Question)?',
            r'Winter\s+\d{4}\s+MATH\s+\d+\s+V\d+,\s+P\d+(?:\s+Question)?',
        ]
        
        cleaned = content
        for pattern in header_patterns:
            cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)
        
        return cleaned.strip()
    
    def _indicates_subproblems_expected(self, content):
        """Check if the problem text indicates that subproblems should follow"""
        
        indicators = [
            r'find the following',
            r'determine the following',
            r'calculate the following',
            r'evaluate the following',
            r'compute the following',
            r'solve the following',
            r'show the following',
            r'prove the following',
        ]
        
        for indicator in indicators:
            if re.search(indicator, content, re.IGNORECASE):
                print(f"   üîç Found subproblem indicator: '{indicator}'")
                return True
        
        return False
    
    def _extract_text_based_subproblems(self, content):
        """Try to extract subproblems from text-based format"""
        
        subproblems = {}
        
        # Try to split on sentences that might be implicit subproblems
        # Look for patterns like mathematical expressions or tasks
        sentences = re.split(r'[.!?]\s+', content)
        
        subproblem_count = 0
        for sentence in sentences:
            sentence = sentence.strip()
            
            # Skip very short sentences or the main problem statement
            if len(sentence) < 10:
                continue
            
            # Skip sentences that are clearly not subproblems
            skip_patterns = [
                r'^Given:',
                r'^Note:',
                r'^Hint:',
                r'find the following',
                r'marks\)',
            ]
            
            should_skip = False
            for skip_pattern in skip_patterns:
                if re.search(skip_pattern, sentence, re.IGNORECASE):
                    should_skip = True
                    break
            
            if should_skip:
                continue
            
            # Check if this sentence contains mathematical content
            if self._is_valid_subproblem_content(sentence):
                subproblem_key = chr(ord('a') + subproblem_count)
                
                # Clean the sentence content
                cleaned_sentence = self._clean_subproblem_content(sentence)
                problem_text, solution = self._extract_solution(cleaned_sentence)
                
                subproblems[subproblem_key] = {
                    "problem_text": self._clean_text(problem_text),
                    "correct_answer": None,
                    "solution": {
                        "text": self._clean_text(solution) if solution else None,
                        "images": []
                    } if solution else None,
                    "images": []
                }
                
                subproblem_count += 1
                print(f"   ‚úÖ Extracted text-based subproblem {subproblem_key}: '{cleaned_sentence[:50]}...'")
                
                # Limit to reasonable number of subproblems
                if subproblem_count >= 6:
                    break
        
        return subproblems if subproblems else {}
    
    def _is_valid_problem_number(self, problem_num):
        """Check if a problem number is in a valid range for exam problems"""
        # Most exams have problems numbered 1-30, but allow wider range for flexibility
        # Filter out common false positives from mathematical expressions
        invalid_numbers = {0, 100, 1000, 10000}  # Common math constants that get misidentified
        if problem_num in invalid_numbers:
            return False
        return 1 <= problem_num <= 50
    
    def _is_valid_problem_sequence(self, problems):
        """Check if the sequence of problems makes sense"""
        if not problems:
            return False
        
        # Extract problem numbers and sort them
        problem_numbers = sorted([p['number'] for p in problems])
        
        # Check for reasonable sequential patterns
        # Allow for some gaps but not too many random numbers
        if len(problem_numbers) == 1:
            return True  # Single problem is always valid
        
        # Check if numbers are somewhat sequential (allow gaps of 1-3)
        gaps = []
        for i in range(1, len(problem_numbers)):
            gap = problem_numbers[i] - problem_numbers[i-1]
            gaps.append(gap)
        
        # Most gaps should be reasonable (1-3), with maybe one larger gap
        reasonable_gaps = [g for g in gaps if 1 <= g <= 3]
        large_gaps = [g for g in gaps if g > 3]
        
        # Accept if most gaps are reasonable
        if len(reasonable_gaps) >= len(gaps) * 0.7:
            return True
        
        # Reject sequences with too many large gaps or invalid numbers
        if len(large_gaps) > 1 or any(g > 10 for g in gaps):
            return False
        
        return True
    
    def _has_math_content(self, content):
        """Check if page has substantial math content"""
        
        # Must have minimum length
        if len(content.strip()) < 50:
            return False
        
        # Check for math symbols and expressions
        math_symbols = [
            r'[+\-*/=<>‚â§‚â•‚â†‚âà]',  # Math operators
            r'[a-zA-Z]\s*[+\-*/]\s*[a-zA-Z]',  # Variable operations
            r'[0-9]+\s*[+\-*/]\s*[0-9]+',  # Numbers with operators
            r'[a-zA-Z]\([a-zA-Z]\)',  # Function notation
            r'[a-zA-Z]\^[0-9]+',  # Exponents
            r'\\[a-zA-Z]+\{.*?\}',  # LaTeX commands
        ]
        
        math_count = 0
        for pattern in math_symbols:
            if re.search(pattern, content):
                math_count += 1
        
        # Must have at least 2 math indicators
        return math_count >= 2
    
    def _combine_page_results(self, all_problems, all_images, id_prefix=None):
        """Combine problems from all pages into final format"""
        
        combined_problems = []
        
        # Group problems by problem number and track their pages
        problems_by_number = {}
        for problem in all_problems:
            num = problem['number']
            if num not in problems_by_number:
                problems_by_number[num] = []
            problems_by_number[num].append(problem)
        
        # Associate orphaned content with problems
        self._associate_orphaned_content_with_problems(problems_by_number)
        
        # Create final problem objects
        for problem_num in sorted(problems_by_number.keys()):
            problem_parts = problems_by_number[problem_num]
            
            # Get all pages this problem appears on
            problem_pages = [p['page'] for p in problem_parts]
            
            # Find the primary page (the one with the actual problem, not answer key)
            # Usually the first occurrence is the actual problem
            primary_problem = problem_parts[0]  # Use the first occurrence
            
            # If there are multiple pages, try to identify which one is the actual problem
            if len(problem_parts) > 1:
                # Choose the earliest page (problem statement usually comes first, not last)
                primary_problem = min(problem_parts, key=lambda p: p['page'])
                print(f"   üîç Problem {problem_num}: Using content from page {primary_problem['page']} (earliest page, length: {len(primary_problem['content'])})")
            
            # Combine content from all pages in order (to handle multi-page problems/solutions)
            problem_parts_sorted = sorted(problem_parts, key=lambda p: p['page'])
            combined_content = '\n'.join([part['content'] for part in problem_parts_sorted])
            
            print(f"   üìÑ Problem {problem_num}: Combined content from {len(problem_parts)} page(s), total length: {len(combined_content)}")
            
            # Extract subproblems from the content
            subproblems = self._extract_subproblems(combined_content)
            
            # Clean the problem text by removing subproblem parts
            cleaned_problem_text = self._clean_problem_text(combined_content, subproblems)
            
            # Remove multiple choice options from problem text
            cleaned_problem_text = self._remove_multiple_choice_options(cleaned_problem_text)
            
            # Extract solution from main problem text if present
            main_problem_text, main_solution = self._extract_solution(cleaned_problem_text)
            
            # Find images for this problem based on page numbers
            problem_images = self._find_problem_images(problem_num, problem_pages, all_images)
            
            # Distribute images between main problem and subproblems
            main_images, subproblems_with_images = self._distribute_images_to_subproblems(
                main_problem_text, subproblems, problem_images)
            
            # Check if any images should belong to solution instead of main problem
            solution_images = []
            if main_solution and main_images:
                # For problems with solutions, check if images appear after "Solution" marker
                solution_images, main_images = self._separate_solution_images(
                    cleaned_problem_text, main_solution, main_images, problem_num
                )
            
            # Create ID with manual prefix
            if id_prefix:
                problem_id = f"{id_prefix}_p{problem_num}"
            else:
                # Fallback to descriptive ID if no prefix provided
                problem_id = self._create_descriptive_id("unknown", problem_num)
            
            final_problem = {
                "id": problem_id,
                "doc_id": id_prefix if id_prefix else "unknown",
                "problem_text": self._clean_text(main_problem_text),
                "subproblems": subproblems_with_images,
                "correct_answer": None,
                "solution": {
                    "text": self._clean_text(main_solution) if main_solution else None,
                    "images": solution_images  # For solution-specific images
                } if main_solution else None,
                "images": main_images,
                "difficulty": None,
                "domain": [],
                "topics": [],
                "math_approach": [],
                "reasoning_type": []
            }
            
            combined_problems.append(final_problem)
        
        return combined_problems
    
    def _associate_orphaned_content_with_problems(self, problems_by_number):
        """Associate orphaned content with the appropriate problems"""
        
        orphaned_content_by_page = getattr(self, 'orphaned_content_by_page', {})
        
        if not orphaned_content_by_page:
            return
            
        # Sort problems by their first page appearance to determine the "last problem" of each page
        all_problems_with_pages = []
        for problem_num, problem_parts in problems_by_number.items():
            first_page = min(p['page'] for p in problem_parts)
            all_problems_with_pages.append((problem_num, first_page))
        
        all_problems_with_pages.sort(key=lambda x: x[1])  # Sort by page
        
        # For each page with orphaned content, find the last problem from the previous page
        for page_num, orphaned_content in orphaned_content_by_page.items():
            # Find the last problem that appears before this page
            last_problem_num = None
            for problem_num, problem_page in all_problems_with_pages:
                if problem_page < page_num:
                    last_problem_num = problem_num
                else:
                    break  # We've passed the current page
            
            if last_problem_num:
                # Create a virtual "problem part" for the orphaned content
                orphaned_part = {
                    'page': page_num,
                    'number': last_problem_num,
                    'content': orphaned_content,
                    'full_text': self._clean_text(orphaned_content),
                    'is_continuation': True
                }
                
                problems_by_number[last_problem_num].append(orphaned_part)
                print(f"   üîó Associated orphaned content from page {page_num} with problem {last_problem_num}")
        
    def _save_image_from_results(self, image_info, images_path, page_num, img_num, associated_problem=None, associated_subproblem=None):
        """Save image from Mathpix results"""
        
        try:
            if 'data' not in image_info:
                return None
            
            image_b64 = image_info['data']
            if image_b64.startswith('data:image'):
                image_b64 = image_b64.split(',')[1]
            
            image_bytes = base64.b64decode(image_b64)
            
            filename = self._generate_problem_based_filename(
                associated_problem, img_num, page_num, associated_subproblem
            )
            file_path = images_path / filename
            
            with open(file_path, 'wb') as f:
                f.write(image_bytes)
            
            print(f"   üíæ Saved image: {filename}")
            return filename
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Could not save image: {e}")
            return None
    
    def _cleanup_temp_files(self, temp_dir):
        """Clean up temporary page images"""
        try:
            import shutil
            if Path(temp_dir).exists():
                shutil.rmtree(temp_dir)
                print("üóëÔ∏è  Cleaned up temporary files")
        except Exception as e:
            print(f"‚ö†Ô∏è Could not clean up temp files: {e}")
    
    def _extract_subproblems(self, content):
        """Extract subproblems from a single problem's content.
        
        Handles multiple formats:
        - a) or b) or c)
        - a. or b. or c.
        - (a) or (b) or (c)
        
        Considers markers at line beginnings OR preceded by whitespace/punctuation.
        """
        subproblems = {}
        
        # Find all potential subproblem markers
        subproblem_markers = []
        
        # Pattern to match subproblem markers with context
        patterns = [
            # a) format - look for letter followed by closing parenthesis
            r'([a-zA-Z])\)',
            # a. format - look for letter followed by period  
            r'([a-zA-Z])\.',
            # (a) format - look for letter inside parentheses
            r'\(([a-zA-Z])\)',
            # i) format - roman numerals
            r'([iv]+)\)',
            # 1) format - numbers followed by parenthesis
            r'(\d+)\)',
        ]
        
        for pattern_idx, pattern in enumerate(patterns):
            pattern_name = ['a)', 'a.', '(a)', 'i)', '1)'][pattern_idx]
            
            for match in re.finditer(pattern, content, re.MULTILINE):
                key = match.group(1).lower()
                marker_text = match.group(0)  # Full matched text (e.g., "a)", "b.", "(c)")
                
                # Get the actual marker position
                marker_start = match.start()
                marker_end = match.end()
                
                # Check if this marker is inside a LaTeX expression
                before_marker = content[:marker_start]
                
                # Count unclosed LaTeX delimiters before this position
                open_inline = before_marker.count('\\(') - before_marker.count('\\)')
                open_display = before_marker.count('\\[') - before_marker.count('\\]')
                open_dollar = before_marker.count('$') % 2  # Odd means we're inside $ $
                
                # Skip if we're inside any LaTeX expression
                if open_inline > 0 or open_display > 0 or open_dollar == 1:
                    continue
                
                # Check if marker is in proper context
                # Look for ". " (dot followed by space) before the marker
                if marker_start >= 2:
                    two_chars_before = content[marker_start - 2:marker_start]
                    dot_space_before = two_chars_before == '. '
                else:
                    dot_space_before = False
                
                char_before = content[marker_start - 1] if marker_start > 0 else '\n'
                is_valid_context = (
                    dot_space_before or  # After ". " (dot followed by space)
                    char_before in ['\n', ' ', '\t'] or  # After newline or whitespace
                    char_before in ['.', '!', '?', ':'] or  # After punctuation
                    marker_start == 0  # At very beginning
                )
                
                if not is_valid_context:
                    continue
                
                # Use the exact match positions 
                actual_start = marker_start
                
                # Avoid duplicates - check if we already found this position
                duplicate = False
                for existing in subproblem_markers:
                    if abs(existing['start'] - actual_start) < 3:  # Within 3 characters
                        duplicate = True
                        break
                
                if not duplicate:
                    subproblem_markers.append({
                        'key': key,
                        'start': actual_start,
                        'end': marker_end,
                        'marker_text': marker_text,
                        'pattern': pattern_name
                    })
                    
                    pass
        
        # Sort markers by position
        subproblem_markers.sort(key=lambda x: x['start'])
        
        # Check if this looks like multiple choice options (exclude them completely)
        if self._is_multiple_choice_sequence(subproblem_markers):
            print(f"   üö´ Detected multiple choice options - excluding from subproblems")
            return {}
        
        # Special handling for problems that indicate subproblems but none were found
        if not subproblem_markers and self._indicates_subproblems_expected(content):
            print(f"   üîç Problem indicates subproblems expected but none found with standard patterns")
            # Try to extract text-based subproblems
            text_subproblems = self._extract_text_based_subproblems(content)
            if text_subproblems:
                return text_subproblems
        
        # Extract subproblem content between markers
        for i, marker in enumerate(subproblem_markers):
            start_pos = marker['end']  # Start after the marker (e.g., after "a)")
            
            # Find the end of this subproblem
            if i + 1 < len(subproblem_markers):
                # End at the next subproblem marker
                end_pos = subproblem_markers[i + 1]['start']
            else:
                # End at the end of the content
                end_pos = len(content)
            
            # Extract the subproblem content
            subproblem_content = content[start_pos:end_pos].strip()
            
            # Remove any trailing newlines and clean up
            subproblem_content = re.sub(r'\n\s*$', '', subproblem_content)
            subproblem_content = subproblem_content.strip()
            
            print(f"   üîç Raw subproblem {marker['key']} content: '{subproblem_content[:100]}...'")
            
            # Basic validation for subproblem content (more lenient than main problems)
            if self._is_valid_subproblem_content(subproblem_content):
                # Clean the subproblem content to remove header patterns
                cleaned_subproblem_content = self._clean_subproblem_content(subproblem_content)
                
                # Extract solution if present
                problem_text, solution = self._extract_solution(cleaned_subproblem_content)
                
                subproblems[marker['key']] = {
                    "problem_text": self._clean_text(problem_text),
                    "correct_answer": None,
                    "solution": {
                        "text": self._clean_text(solution) if solution else None,
                        "images": []  # For solution-specific images
                    } if solution else None,
                    "images": []
                }
                if solution:
                    print(f"   ‚úÖ Extracted subproblem {marker['key']} with solution")
                else:
                    print(f"   ‚úÖ Extracted subproblem {marker['key']}")
            else:
                print(f"   ‚ö†Ô∏è Subproblem {marker['key']} failed validation")
        
        return subproblems
    
    def _is_multiple_choice_sequence(self, markers):
        """Detect if markers represent multiple choice options rather than real subproblems"""
        if len(markers) < 4:  # Multiple choice typically has 4+ options
            return False
        
        # Get the keys (letters) from markers
        keys = [marker['key'] for marker in markers]
        
        # Check if we have sequential letters starting from 'a'
        expected_sequence = [chr(ord('a') + i) for i in range(len(keys))]
        
        # If we have 4+ sequential letters starting from 'a', it's likely multiple choice
        if keys == expected_sequence:
            print(f"   üîç Sequential pattern detected: {keys}")
            return True
        
        # Also check if we have 4+ letters that are mostly sequential (allowing some gaps)
        # This handles cases like a, c, e, g (where b, d, f might be missing)
        if len(keys) >= 4:
            # Convert letters to numbers for easier analysis
            letter_nums = [ord(k) - ord('a') for k in keys]
            letter_nums.sort()
            
            # If the range spans 4+ positions and we have 4+ items, likely multiple choice
            if letter_nums[-1] - letter_nums[0] >= 3 and len(letter_nums) >= 4:
                print(f"   üîç Multiple choice pattern detected: {keys}")
                return True
        
        return False
    
    def _find_problem_images(self, problem_num, problem_pages, all_images):
        """Find images that are associated with a specific problem based on content analysis"""
        
        problem_images = []
        
        # Use the new association logic based on content analysis
        for img in all_images:
            # Check if this image is associated with our problem
            associated_problem = img.get('associated_problem')
            
            if associated_problem == problem_num:
                # This image was specifically associated with our problem
                problem_images.append(img['filename'])
            elif associated_problem is None and img.get('page') in problem_pages:
                # Fallback: if no specific association, include images from problem pages
                # but only if there's only one problem on that page
                page_problems = [p for p in problem_pages if p == img.get('page')]
                if len(page_problems) == 1:
                    problem_images.append(img['filename'])
        
        return problem_images
    
    def _create_descriptive_id(self, pdf_path, problem_num):
        """Create a descriptive ID based on PDF filename and problem number"""
        
        # Extract base filename without extension
        pdf_name = Path(pdf_path).stem
        
        # Clean up the filename to make it more readable
        # Remove common patterns and replace with underscores
        clean_name = re.sub(r'[^\w\s-]', '', pdf_name)  # Remove special chars
        clean_name = re.sub(r'\s+', '_', clean_name)     # Replace spaces with underscores
        clean_name = re.sub(r'_+', '_', clean_name)      # Replace multiple underscores with single
        clean_name = clean_name.lower()                   # Convert to lowercase
        
        # Remove common prefixes/suffixes
        clean_name = re.sub(r'^(final|exam|test|quiz|hw|homework)_', '', clean_name)
        clean_name = re.sub(r'_(final|exam|test|quiz|hw|homework)$', '', clean_name)
        
        # Create the descriptive ID
        descriptive_id = f"{clean_name}_problem_{problem_num}"
        
        return descriptive_id
    
    def _clean_text(self, text):
        """Clean up extracted text"""
        
        # Remove page markers
        text = re.sub(r'--- PAGE \d+ ---', '', text)
        
        # HTML escape inequality symbols to prevent HTML parsing issues
        text = self._html_escape_math_symbols(text)
        
        # Remove common metadata patterns
        metadata_patterns = [
            r'Gstudocu.*?Studocu.*?university',
            r'Downloaded by.*?@.*?\.com',
            r'Scan to open on Studocu',
            r'Studocu is not sponsored.*?university',
            r'Introduction to Calculus.*?University of Pennsylvania',
            r'103finalfall 2014 withans',
            r'Page \d+ of \d+',
            r'¬©.*?All rights reserved',
            r'Confidential',
            r'Draft',
            r'Final Exam',
            r'Name:.*?',
            r'Student ID:.*?',
            r'Date:.*?',
            r'Time:.*?',
            r'Instructions:.*?',
            r'Total Points:.*?',
            r'Show all work',
            r'No calculators allowed',
            r'Good luck',
            r'jeremywu12345@gmail\.com',
            r'jeremywu12345',
            # McGill header patterns
            r'\)\s*Winter\s+\d{4}\s+MATH\s+\d+\s+V\d+,\s+P\d+(?:\s+Question)?',
            r'Winter\s+\d{4}\s+MATH\s+\d+\s+V\d+,\s+P\d+(?:\s+Question)?',
            # McGill exam instructions and metadata
            r'Course:\s*MATH\s*\d+.*?Page number:\s*\d+\s*of\s*\d+',
            r'INSTRUCTIONS\s*-\s*You have until.*?enjoy the summer!',
            r'You have until.*?submit it on myCourses.*?No late submissions will be accepted',
            r'All solutions should be your own.*?solve the problems',
            r'Show and justify each step.*?simplify the answers',
            r'You may answer the questions directly.*?single PDF file',
            r'Stay safe and enjoy the summer!',
            # Exam instructions and metadata
            r'University of Pennsylvania.*?Math 103.*?Fall 2014',
            r'Name.*?PRINT.*?Professor.*?Rimmer.*?Wong.*?Towsner',
            r'Penn ID.*?Recitation Number.*?Rec\. Day.*?Rec\. Time',
            r'This exam has.*?multiple choice questions.*?open-ended questions',
            r'Each question is worth.*?points',
            r'Partial credit will be given.*?supporting work',
            r'correct answer with little or no supporting work.*?little or no credit',
            r'Use the space provided.*?scrap paper is provided',
            r'If you write on the back.*?indicate this in some way',
            r'You have 120 minutes.*?complete the exam',
            r'You are not allowed.*?calculator.*?electronic device',
            r'You are allowed to use.*?handwritten notes',
            r'Please silence.*?electronic devices',
            r'When you finish.*?120 minutes has elapsed',
            r'When time is up.*?collect your exam',
            r'Once you have completed.*?academic integrity statement',
            r'Do NOT write in the grid.*?grading purposes only',
            r'\\begin\{tabular\}.*?\\end\{tabular\}',
            r'My signature below.*?Academic Integrity.*?examination paper',
            r'Name \(printed\).*?Score.*?Signature.*?Date',
            r'Problem.*?Points.*?Problem.*?Points',
            r'\\hline.*?\\hline',
            r'\\\\.*?\\\\',
        ]
        
        for pattern in metadata_patterns:
            text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.DOTALL)
        
        # Clean up whitespace
        text = re.sub(r'\s+', ' ', text)
        
        # Remove common artifacts
        text = re.sub(r'^\s*\d+\.\s*', '', text)  # Remove leading "1. "
        
        # Clean up excessive whitespace but preserve question marks at the end
        text = text.strip()
        # Don't strip question marks - they're important punctuation
        
        return text
    
    def _html_escape_math_symbols(self, text):
        """Escape HTML special characters in mathematical expressions to prevent rendering issues"""
        
        # Replace < and > with HTML entities to prevent browser from interpreting them as HTML tags
        # This is especially important for mathematical inequalities like "a<b<c"
        text = text.replace('<', '&lt;')
        text = text.replace('>', '&gt;')
        
        return text

    def _clean_problem_text(self, content, subproblems):
        """Clean up the problem text by removing subproblem parts."""
        cleaned_text = content
        
        # Remove subproblem markers and content from the main problem text
        if subproblems:
            # Find the first subproblem marker in the content
            first_marker_pos = len(cleaned_text)  # Start with end of content
            
            for subproblem_key in subproblems.keys():
                # Look for different subproblem marker patterns:
                # 1. a) format
                pattern1 = rf'(^|\s){re.escape(subproblem_key)}\)'
                # 2. a. format  
                pattern2 = rf'(^|\s){re.escape(subproblem_key)}\.'
                # 3. (a) format
                pattern3 = rf'(^|\s)\({re.escape(subproblem_key)}\)'
                
                # Try each pattern
                for pattern in [pattern1, pattern2, pattern3]:
                    match = re.search(pattern, cleaned_text, re.IGNORECASE | re.MULTILINE)
                    
                    if match:
                        # Get the position of the actual marker (not the leading whitespace)
                        marker_pos = match.start()
                        if match.group(1):  # If there was leading whitespace/newline
                            marker_pos = match.start() + len(match.group(1))
                        
                        if marker_pos < first_marker_pos:
                            first_marker_pos = marker_pos
                        break  # Found a match, no need to try other patterns for this key
            
            # If we found any subproblem markers, cut the text before the first one
            if first_marker_pos < len(cleaned_text):
                cleaned_text = cleaned_text[:first_marker_pos]
        
        return cleaned_text.strip()

    def _remove_multiple_choice_options(self, content):
        """Remove multiple choice options (a), b), c), etc.) from problem text"""
        
        # Find all potential multiple choice markers
        mc_markers = []
        
        # Pattern to match multiple choice markers
        patterns = [
            r'([a-zA-Z])\)',  # a), b), c)
            r'([a-zA-Z])\.',  # a., b., c.
            r'\(([a-zA-Z])\)' # (a), (b), (c)
        ]
        
        for pattern in patterns:
            for match in re.finditer(pattern, content, re.MULTILINE):
                key = match.group(1).lower()
                marker_start = match.start()
                
                # Skip if inside LaTeX
                before_marker = content[:marker_start]
                open_inline = before_marker.count('\\(') - before_marker.count('\\)')
                open_display = before_marker.count('\\[') - before_marker.count('\\]')
                open_dollar = before_marker.count('$') % 2
                
                if open_inline > 0 or open_display > 0 or open_dollar == 1:
                    continue
                
                # Check context - should be preceded by whitespace/punctuation
                char_before = content[marker_start - 1] if marker_start > 0 else '\n'
                if char_before in ['\n', ' ', '\t', '.', '!', '?', ':'] or marker_start == 0:
                    mc_markers.append({
                        'key': key,
                        'start': marker_start,
                        'marker_text': match.group(0)
                    })
        
        # Sort by position
        mc_markers.sort(key=lambda x: x['start'])
        
        # Check if this looks like multiple choice (4+ options)
        if len(mc_markers) >= 4:
            keys = [marker['key'] for marker in mc_markers]
            
            # Check for sequential pattern
            expected_sequence = [chr(ord('a') + i) for i in range(len(keys))]
            is_sequential = keys == expected_sequence
            
            # Or check for mostly sequential pattern
            if not is_sequential and len(keys) >= 4:
                letter_nums = [ord(k) - ord('a') for k in keys]
                letter_nums.sort()
                is_sequential = letter_nums[-1] - letter_nums[0] >= 3
            
            if is_sequential:
                # Remove everything from the first multiple choice marker onward
                first_mc_pos = mc_markers[0]['start']
                cleaned_text = content[:first_mc_pos]
                
                # Clean up trailing whitespace and some punctuation, but preserve question marks
                cleaned_text = cleaned_text.rstrip(' \t\n:')
                
                print(f"   üßπ Removed multiple choice options from problem text")
                return cleaned_text.strip()
        
        return content

    def _distribute_images_to_subproblems(self, main_problem_text, subproblems, all_images):
        """Distribute images between main problem and subproblems based on content analysis"""
        
        main_images = []
        updated_subproblems = {}
        
        # Create a copy of subproblems to update with images
        for key, subproblem in subproblems.items():
            updated_subproblems[key] = subproblem.copy()
            if "images" not in updated_subproblems[key]:
                updated_subproblems[key]["images"] = []
        
        # Analyze each image to determine its association
        for image_filename in all_images:
            associated_subproblem = self._determine_image_subproblem_association(
                image_filename, main_problem_text, subproblems)
            
            if associated_subproblem:
                updated_subproblems[associated_subproblem]["images"].append(image_filename)
                print(f"   üñºÔ∏è Associated image {image_filename} with subproblem {associated_subproblem}")
            else:
                main_images.append(image_filename)
                print(f"   üñºÔ∏è Associated image {image_filename} with main problem text")
        
        return main_images, updated_subproblems
    
    def _determine_image_subproblem_association(self, image_filename, main_problem_text, subproblems):
        """Determine which subproblem an image belongs to based on content and filename analysis"""
        
        # Method 1: Filename pattern analysis (e.g., "p6_b_1.png" -> subproblem b)
        filename_match = re.search(r'p\d+_([a-z])_\d+\.png', image_filename)
        if filename_match:
            subproblem_key = filename_match.group(1)
            if subproblem_key in subproblems:
                print(f"   üîç Filename pattern suggests {image_filename} belongs to subproblem {subproblem_key}")
                return subproblem_key
        
        # Method 2: Content analysis - look for visual cues in subproblem text
        image_keywords = [
            'shaded region', 'graph', 'figure', 'diagram', 'chart', 'below', 'above',
            'shown', 'illustrated', 'picture', 'image', 'plot', 'curve', 'line'
        ]
        
        best_match = None
        max_matches = 0
        
        for subproblem_key, subproblem_data in subproblems.items():
            subproblem_text = subproblem_data.get('problem_text', '')
            match_count = 0
            
            for keyword in image_keywords:
                if keyword.lower() in subproblem_text.lower():
                    match_count += 1
                    print(f"   üîç Found image keyword '{keyword}' in subproblem {subproblem_key}")
            
            if match_count > max_matches:
                max_matches = match_count
                best_match = subproblem_key
        
        # Method 3: Special cases - if main problem is empty/short, likely belongs to a subproblem
        if not main_problem_text.strip() and len(subproblems) == 1:
            # If main problem is empty and there's only one subproblem, image likely belongs there
            return list(subproblems.keys())[0]
        
        return best_match if max_matches > 0 else None

    def _extract_solution(self, content):
        """Extract solution from content, separating problem text from solution.
        
        Returns:
            tuple: (problem_text, solution) where solution is None if not found
        """
        
        # Look for solution markers with word boundaries to avoid false matches
        solution_patterns = [
            r'\bSolution[:\.]\s*',      # "Solution:" or "Solution." with optional space
            r'\bAnswer[:\.]\s*',        # "Answer:" or "Answer." with optional space  
            r'\bSol[:\.]\s*',          # "Sol:" or "Sol." with optional space
            r'\bSolution\s*:',          # "Solution :" with space before colon
            r'\bAnswer\s*:',            # "Answer :" with space before colon
        ]
        
        best_match = None
        best_position = len(content)
        
        for pattern in solution_patterns:
            # Use case-insensitive search to find solution marker
            match = re.search(pattern, content, re.IGNORECASE)
            
            if match and match.start() < best_position:
                best_match = match
                best_position = match.start()
        
        if best_match:
            # Split content at the solution marker
            problem_text = content[:best_match.start()].strip()
            solution_text = content[best_match.end():].strip()
            
            # Clean up the problem text (remove trailing whitespace and periods, but keep question marks)
            problem_text = problem_text.rstrip(' .:')
            
            if solution_text:
                print(f"   üìù Found solution (length: {len(solution_text)} chars)")
                return problem_text, solution_text
            else:
                print(f"   ‚ö†Ô∏è Solution marker found but no solution content")
                return problem_text, None
        
        # No solution found
        return content, None

    def _parse_prefix_metadata(self, id_prefix):
        """Parse the prefix to extract metadata fields"""
        if not id_prefix:
            return {
                "id": "unknown",
                "school": "unknown",
                "course": "unknown", 
                "problem_type": "unknown",
                "term": "unknown",
                "year": "unknown"
            }
        
        # Split by underscores
        parts = id_prefix.split('_')
        
        # Extract each field, defaulting to "unknown" if not available
        metadata = {
            "id": id_prefix,
            "school": parts[0] if len(parts) > 0 else "unknown",
            "course": parts[1] if len(parts) > 1 else "unknown",
            "problem_type": parts[2] if len(parts) > 2 else "unknown", 
            "term": parts[3] if len(parts) > 3 else "unknown",
            "year": parts[4] if len(parts) > 4 else "unknown"
        }
        
        return metadata

    def _generate_problem_based_filename(self, associated_problem, img_num, page_num, subproblem=None):
        """Generate filename based on problem number, with optional subproblem, fallback to page-based naming"""
        
        if associated_problem:
            if subproblem:
                # Use problem + subproblem naming: p{problem_num}_{img_num}_{subproblem}.png
                filename = f"p{associated_problem}_{img_num}_{subproblem}.png"
                print(f"   üìù Generated problem+subproblem filename: {filename}")
            else:
                # Use problem-based naming: p{problem_num}_{img_num}.png
                filename = f"p{associated_problem}_{img_num}.png"
                print(f"   üìù Generated problem-based filename: {filename}")
        else:
            # Fallback to page-based naming for unassociated images
            filename = f"page_{page_num}_img_{img_num}.png"
            print(f"   üìù Generated page-based filename (fallback): {filename}")
        
        return filename

    def _detect_subproblem_for_image(self, page_num, problem_num, img_idx):
        """Detect which subproblem an image belongs to based on content analysis"""
        
        try:
            # This is a simplified implementation that could be enhanced
            # For now, we'll use heuristics based on known patterns
            
            # Check if we have content analysis available for this page
            # In a more sophisticated implementation, we would analyze the actual
            # problem text around the image position to detect subproblem markers
            
            print(f"   üîç Attempting subproblem detection for problem {problem_num}, image {img_idx}")
            
            # For demonstration, we can use some basic heuristics:
            # - If there are multiple images for the same problem, they might be for different subproblems
            # - We could analyze the problem text that was extracted to find subproblem markers
            
            # This is a placeholder implementation
            # In practice, you would want to:
            # 1. Get the extracted text for this problem
            # 2. Find subproblem markers (a), b), c), etc.
            # 3. Determine which subproblem the image is closest to based on position
            
            # For now, return None (no subproblem detected)
            # This can be enhanced with actual content analysis
            
            return None
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error detecting subproblem for image: {e}")
            return None

    def _separate_solution_images(self, problem_text, solution_text, images, problem_num):
        """Separate images that belong to solution from main problem images"""
        
        solution_images = []
        main_images = []
        
        # For now, use a simple heuristic: if there's a solution and images,
        # and the problem text doesn't mention graphs/figures, images likely belong to solution
        image_keywords = ['graph', 'figure', 'diagram', 'chart', 'below', 'above', 
                         'shown', 'illustrated', 'picture', 'image', 'plot', 'curve', 'line',
                         'shaded region', 'shaded area']
        
        problem_mentions_image = any(keyword in problem_text.lower() for keyword in image_keywords)
        solution_mentions_image = any(keyword in solution_text.lower() for keyword in image_keywords) if solution_text else False
        
        for img in images:
            # If problem mentions images, keep in main; if only solution mentions images, move to solution
            if not problem_mentions_image and solution_mentions_image:
                solution_images.append(img)
                print(f"   üñºÔ∏è Moving image {img} to solution for problem {problem_num}")
            else:
                main_images.append(img)
        
        return solution_images, main_images

    def _is_header_image(self, pdf_doc, page_num, xref):
        """Check if an image is likely a header image based on position and size"""
        
        try:
            page = pdf_doc[page_num - 1]  # Convert to 0-based index
            
            # Get page dimensions
            page_rect = page.rect
            page_width = page_rect.width
            page_height = page_rect.height
            
            # Get all image instances on the page
            img_list = page.get_images()
            
            # Find the specific image
            for img in img_list:
                if img[0] == xref:
                    # Get image position on page
                    img_rects = page.get_image_rects(xref)
                    
                    if img_rects:
                        for rect in img_rects:
                            # Check if image is in the top portion of the page
                            img_top = rect.y0
                            img_height = rect.height
                            img_width = rect.width
                            img_center_x = (rect.x0 + rect.x1) / 2
                            
                            # Header criteria (more conservative):
                            # 1. Located in top 10% of page (was 15%)
                            # 2. Small height (less than 8% of page height) (was 10%)
                            # 3. Located in the right half of the page (for PENN ID box)
                            # 4. Must satisfy BOTH top region AND (small height OR right side)
                            is_top_region = img_top < (page_height * 0.10)  # More conservative
                            is_small_height = img_height < (page_height * 0.08)  # More conservative  
                            is_right_side = img_center_x > (page_width * 0.5)
                            
                            # Require stricter criteria - must be small AND in top region
                            if is_top_region and is_small_height and is_right_side:
                                print(f"   üéØ Detected header image at top of page (y={img_top:.1f}, height={img_height:.1f})")
                                return True
                            
                            # Also check if it's a very small rectangular image (like PENN ID box) - more conservative
                            aspect_ratio = img_width / img_height if img_height > 0 else 0
                            is_rectangular = 2.0 < aspect_ratio < 4.0  # More restrictive aspect ratio
                            is_very_small = img_height < 40 and img_width < 120  # Smaller thresholds
                            
                            # Only filter if it's very clearly a header (small, rectangular, top-right)
                            if is_top_region and is_rectangular and is_very_small and is_right_side:
                                print(f"   üéØ Detected small rectangular header image (aspect ratio={aspect_ratio:.2f})")
                                return True
            
            return False
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error checking if image is header: {e}")
            return False



def main():
    """Example usage"""
    
    # Set up command line argument parsing
    parser = argparse.ArgumentParser(description='Convert PDF to JSON with math problems')
    parser.add_argument('--pdf', '-p', type=str, default="../data/103finalf14.pdf", 
                       help='Path to the PDF file (default: ../data/103finalf14.pdf)')
    parser.add_argument('--prefix', '-i', type=str, required=True,
                       help='ID prefix for the problems (e.g., math103_final_fall2014)')
    parser.add_argument('--output', '-o', type=str, default="output",
                       help='Output directory (default: output)')
    
    args = parser.parse_args()
    
    # Load credentials from environment variables
    APP_ID = os.getenv('MATHPIX_APP_ID')
    APP_KEY = os.getenv('MATHPIX_APP_KEY')
    
    if not APP_ID or not APP_KEY:
        print("‚ùå Error: MATHPIX_APP_ID and MATHPIX_APP_KEY must be set in .env file")
        print("Create a .env file in the root directory with:")
        print("MATHPIX_APP_ID=your_app_id_here")
        print("MATHPIX_APP_KEY=your_app_key_here")
        return
    
    print(f"‚úÖ Loaded Mathpix credentials from .env file")
    
    # Initialize converter
    converter = SinglePDFConverter(APP_ID, APP_KEY)
    
    # Check if PDF file exists
    if not os.path.exists(args.pdf):
        print(f"‚ùå File not found: {args.pdf}")
        print("Make sure the PDF file exists at the specified path")
        return
    
    print(f"üìÅ Found PDF file: {args.pdf}")
    print(f"üè∑Ô∏è  Using ID prefix: {args.prefix}")
    
    # Convert the PDF
    json_output = converter.convert_pdf(args.pdf, args.output, args.prefix)
    
    if json_output:
        print(f"\nüéâ Success! Check the output:")
        print(f"üìÑ JSON file: {json_output}")
        # Extract the folder path from json_output and add images subfolder
        output_folder = str(Path(json_output).parent)
        print(f"üñºÔ∏è  Images folder: {output_folder}/images/")
    else:
        print("\n‚ùå Conversion failed")

if __name__ == "__main__":
    main()